{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix representation of operators\n",
    "\n",
    "We saw briefly that we can represent finite difference operators as matrices. Let's look at this in a bit more detail.\n",
    "\n",
    "To do this, we need to provide an ordering of all of the degrees of freedom (dofs) in our finite difference discretisation. In one dimension, we order the points in the domain from left to right and use a single index:\n",
    "\n",
    "$$\n",
    "x_0 < x_1 < \\dots < x_{n-1}\n",
    "$$\n",
    "\n",
    "and so we have a single index for all the points $i = [0, 1, \\dots, n-1]$. We can therefore represent our function $u(x)$ discretised at the points $\\{x_i\\}$ as a vector in $\\mathbb{R}^n$\n",
    "\n",
    "$$\n",
    "U = \\begin{bmatrix} u_0 \\\\ u_1 \\\\ \\vdots \\\\ u_{n-1} \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "and similarly with the right hand side $f(x)$. The differencing operators *combine* entries from $U$ linearly to produce a new vector $D U$. Since this operation is linear, we can represent it as a matrix\n",
    "\n",
    "$$\n",
    "D : \\mathbb{R}^n \\to \\mathbb{R}^n\n",
    "$$\n",
    "\n",
    "which takes in a vector $U$ and spits out a new vector representing the action of the differencing operator on $U$.\n",
    "\n",
    "For example, the left-looking operator $D_- u_i = \\frac{u_i - u_{i-1}}{h}$ uses, at each point $i$ values from points $i$ and $i-1$. On a grid with 4 points, this can be represented as the matrix\n",
    "\n",
    "$$\n",
    "D_- = \\frac{1}{h}\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 & 0\\\\\n",
    "-1 & 1 & 0 & 0\\\\\n",
    "0 & -1 & 1 & 0\\\\\n",
    "0 & 0 & -1 & 1\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Similarly, the centered difference approximation of $\\frac{\\text{d}^2}{\\text{d} x^2}$, $D^2 u_i = \\frac{u_{i+1} - 2u_i + u_{i-1}}{h^2}$ can be written\n",
    "\n",
    "$$\n",
    "D^2 = \\frac{1}{h^2}\n",
    "\\begin{bmatrix}\n",
    "-2 & 1 & 0 & 0\\\\\n",
    "1 & -2 & 1 & 0\\\\\n",
    "0 & 1 & -2 & 1\\\\\n",
    "0 & 0 & 1 & -2\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "### \"Matrix-free\" implementation\n",
    "\n",
    "If we only never need to apply the differencing operator, it might make sense (memory or efficiency, for example) to just provide a function which computes the matrix-vector multiplication without storing the matrix. Let's see this in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "pyplot.style.use('ggplot')\n",
    "\n",
    "def dminus(u, h):\n",
    "    n, = u.shape\n",
    "    du = numpy.zeros_like(u)\n",
    "    for i in range(n):\n",
    "        if i == 0:\n",
    "            du[i] = 1/h * u[i]\n",
    "        else:\n",
    "            du[i] = 1/h * (u[i] - u[i-1])\n",
    "    return du\n",
    "\n",
    "def dminusop(u, h):\n",
    "    n, = u.shape\n",
    "    D = numpy.eye(n) - numpy.diag(numpy.full(n-1, 1), k=-1)\n",
    "    D *= 1/h\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "u = numpy.random.rand(n)\n",
    "h = 1/n\n",
    "dminus(u, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = dminusop(u, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D @ u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.allclose(D@u, dminus(u, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which one is faster? Let's have a go with a bigger grid. We can use notebook \"magic\" `%%timeit` to time the execution of a cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "u = numpy.random.rand(n)\n",
    "h = 1/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "dminus(u, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = dminusop(u, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "D @ u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps surprisingly, the python loops are faster than the numpy matrix-vector product. This is likely because the numpy matrix is 10000 x 10000 and dense (and we do a lot of work multiplying by zero). We should probably use a *sparse* matrix (see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also attempt to speed up the loop by using the Python JIT compiler [numba](https://numba.pydata.org) (available via `pip install numba`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "\n",
    "@numba.jit\n",
    "def dminus_compiled(u, h):\n",
    "    n, = u.shape\n",
    "    du = numpy.zeros_like(u)\n",
    "    for i in range(n):\n",
    "        if i == 0:\n",
    "            du[i] = 1/h * u[i]\n",
    "        else:\n",
    "            du[i] = 1/h * (u[i] - u[i-1])\n",
    "    return du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "dminus_compiled(u, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearly a 500x speedup. This doesn't work for all functions, but if you have code with loops and numpy arrays, it's probably worth a shot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D finite differences\n",
    "\n",
    "Now, finally, let's look at finite differences in 2D. We remind ourselves of the differential operators we might encounter. Rather than just a derivative in the $x$ direction, we can take derivatives of a function in both $x$ and $y$.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\partial_x u &= \\frac{\\partial u(x, y)}{\\partial x}\\\\\n",
    "\\partial_y u &= \\frac{\\partial u(x, y)}{\\partial y}\n",
    "\\end{aligned}.\n",
    "$$\n",
    "\n",
    "Often we see vector-calculus operators.\n",
    "\n",
    "### Gradient\n",
    "\n",
    "For a scalar $u(x, y)$ the 2D gradient is a vector\n",
    "\n",
    "$$\n",
    "\\nabla u(x, y) := \\begin{bmatrix} \\partial_x u \\\\ \\partial_y u \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "### Divergence\n",
    "\n",
    "For a vector $\\vec{w}(x, y) = \\begin{bmatrix} w_0 \\\\ w_1 \\end{bmatrix}$, the divergence is a scalar\n",
    "\n",
    "$$\n",
    "\\nabla \\cdot \\vec{w} = \\partial_x w_0 + \\partial_y w_1.\n",
    "$$\n",
    "\n",
    "### Laplacian\n",
    "\n",
    "For a scalar $u(x, y)$ the Laplacian is a scalar\n",
    "\n",
    "$$\n",
    "\\nabla^2 u(x, y) := \\nabla \\cdot \\nabla u(x, y) = \\partial_x^2 u + \\partial_y^2 u.\n",
    "$$\n",
    "\n",
    "### Finite difference operators\n",
    "\n",
    "As usual, we need some domain $\\Omega$ in which we will solve the problem. Given some domain, we need to choose a way of specifying it, and ordering the degrees of freedom. This is very fiddly for anything other than coordinate aligned rectangular domains (one of the major disadvantages of finite differences). As a result, all of the problems we will solve will be on squares and rectangles.\n",
    "\n",
    "Lets choose $\\Omega = (0, W) \\times (0, H)$. We'll pick $N_x$ points in the x-direction, and $N_y$ in the y-direction. We'll choose a typewriter ordering of degrees of freedom (bottom-to-top, left-to-right), so given an index $i$ in the x-direction and an index $j$ in the y-direction it represents the point\n",
    "\n",
    "$$\n",
    "(x, y) = (i h_x, j h_y)\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "h_x &= \\frac{W}{N_x - 1}\\\\\n",
    "h_y &= \\frac{H}{N_y - 1}\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "and $i \\in \\{0, \\dots, N_x - 1\\}$, $j \\in \\{0, \\dots, N_y - 1\\}$.\n",
    "\n",
    "We will again represent our solution vectors as 1D vectors (remembering that we should plot them in 2D).\n",
    "\n",
    "Let's write some code to encapsulate a domain and draw vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Point = namedtuple(\"Point\", (\"x\", \"y\"))\n",
    "\n",
    "class Grid(object):\n",
    "    def __init__(self, Nx, Ny, P0=Point(0,0), P1=Point(1,1)):\n",
    "        X0, Y0 = P0\n",
    "        X1, Y1 = P1\n",
    "        self.W = X1 - X0\n",
    "        self.H = Y1 - Y0\n",
    "        self.Nx = Nx\n",
    "        self.Ny = Ny\n",
    "        x = numpy.linspace(X0, X1, self.Nx)\n",
    "        y = numpy.linspace(Y0, Y1, self.Ny)\n",
    "        self.XY = numpy.meshgrid(x, y, indexing=\"ij\")\n",
    "    \n",
    "    @property\n",
    "    def ndof(self):\n",
    "        return self.Nx*self.Ny\n",
    "\n",
    "    @property\n",
    "    def hx(self):\n",
    "        return self.W/(self.Nx - 1)\n",
    "    \n",
    "    @property\n",
    "    def hy(self):\n",
    "        return self.H/(self.Ny - 1)\n",
    "\n",
    "    def alpha(self, i, j):\n",
    "        return i*self.Ny + j\n",
    "\n",
    "    def new_vector(self, components=1):\n",
    "        vec = numpy.zeros(self.Nx*self.Ny*components, dtype=float)\n",
    "        shape = (self.Nx, self.Ny)\n",
    "        if components > 1:\n",
    "            shape = shape + (components, )\n",
    "        return vec.reshape(shape)\n",
    "    \n",
    "    def contourf(self, u, levels=11):\n",
    "        U = u.reshape(self.Nx, self.Ny)\n",
    "        pyplot.figure()\n",
    "        \n",
    "        pyplot.contourf(*self.XY, U, levels)\n",
    "        pyplot.colorbar()\n",
    "        \n",
    "    def quiver(self, u, colour=None):\n",
    "        U = u.reshape(self.Nx, self.Ny, 2)\n",
    "        pyplot.figure()\n",
    "        if colour is None:\n",
    "            pyplot.quiver(*self.XY, U[..., 0], U[..., 1])\n",
    "        else:\n",
    "            pyplot.quiver(*self.XY, U[..., 0], U[..., 1], colour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = Grid(17, 15, P0=Point(-2, -1), P1=Point(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = grid.XY\n",
    "u = grid.new_vector(components=2)\n",
    "u[..., 0] = -Y\n",
    "u[..., 1] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.quiver(u);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we return vectors that we can index with two indices (or three if we have a vector). For 2D indexing of a vector, I'll write (using roman indices):\n",
    "\n",
    "$$\n",
    "U_{i, j}\n",
    "$$\n",
    "\n",
    "to indicate the value at $(i h_x, j h_y)$.\n",
    "\n",
    "We can translate these 2D indices into a 1D index to a flat vector. I'll use greek letters for these flat indices.\n",
    "\n",
    "$$\n",
    "\\alpha(i, j) := i N_y + j\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's think about solving an equation, we'll start by solving the 2D Laplacian with Dirichlet conditions.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "-\\nabla^2 u &= f && \\text{ on }\\Omega = (0, 1) \\times (0, 1)\\\\\n",
    "         u &= g && \\text{ on }\\partial\\Omega\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We'll pick $f = 8\\pi^2\\sin(2\\pi x)\\sin(2\\pi y)$ and set $g = 0$.\n",
    "\n",
    "Since we're only doing things on axis-aligned domains, the derivatives decompose into directional derivatives, and so the 2D stencil is just the \"sum\" of the two 1D stencils for $\\partial_x^2$ and $\\partial_y^2$. Note that we must be careful to use the correct $h_x$ or $h_y$.\n",
    "\n",
    "So we have\n",
    "\n",
    "$$\n",
    "-\\nabla^2 = \\frac{1}{h_x^2} \\begin{bmatrix} & & \\\\ -1 & 2 & -1 \\\\ & & \\end{bmatrix} + \\frac{1}{h_y^2} \\begin{bmatrix} & -1 & \\\\ & 2 & \\\\ & -1 & \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Where this stencil notation is to be understood as being laid over the 2D grid. We will come to the indexing in a moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian(grid, f, g):\n",
    "    ndof = grid.ndof\n",
    "    A = numpy.zeros((ndof, ndof))\n",
    "    X, Y = grid.XY\n",
    "    u0 = g(X, Y)\n",
    "    rhs = f(X, Y)\n",
    "    stencilx = 1/grid.hx**2 * numpy.array([-1, 0, 2, 0, -1])\n",
    "    stencily = 1/grid.hy**2 * numpy.array([0, -1, 2, -1, 0])\n",
    "    stencil = stencilx + stencily\n",
    "    for i in range(grid.Nx):\n",
    "        for j in range(grid.Ny):\n",
    "            row = grid.alpha(i, j)\n",
    "            if i in (0, grid.Nx - 1) or j in {0, grid.Ny - 1}:\n",
    "                # Dirichlet bc\n",
    "                A[row, row] = 1\n",
    "                rhs[i, j] = u0[i, j]\n",
    "            else:\n",
    "                cols = [grid.alpha(*ij) for ij in\n",
    "                        [(i-1, j), (i, j-1), (i, j), (i, j+1), (i+1, j)]]\n",
    "                A[row, cols] = stencil\n",
    "    return A, rhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = Grid(41, 41)\n",
    "f = lambda x, y: 8*numpy.pi**2*numpy.sin(2*numpy.pi*x)*numpy.sin(2*numpy.pi*y)\n",
    "g = lambda x, y: numpy.zeros_like(x)\n",
    "A, rhs = laplacian(grid, f, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure()\n",
    "pyplot.spy(A);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = numpy.linalg.solve(A, rhs.flatten())\n",
    "grid.contourf(x, levels=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at convergence. We conveniently picked a problem for which the exact solution is easy to compute\n",
    "\n",
    "$$\n",
    "u^*(x, y) = \\sin(2\\pi x)\\sin(2\\pi y).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mms_errors(ncell, f, g):\n",
    "    errors = []\n",
    "    for n in ncell:\n",
    "        grid = Grid(n + 1, n + 1)\n",
    "        A, rhs = laplacian(grid, f, g)\n",
    "        u = numpy.linalg.solve(A, rhs.flatten())\n",
    "        X, Y = grid.XY\n",
    "        uexact = numpy.sin(2*numpy.pi*X)*numpy.sin(2*numpy.pi*Y)\n",
    "        u = u.reshape(uexact.shape)\n",
    "        error = u - uexact\n",
    "        error = numpy.sqrt(grid.hx*grid.hy)*numpy.linalg.norm(error)\n",
    "        errors.append(error)\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncell = numpy.geomspace(4, 64, num=5, dtype=int)\n",
    "errors = mms_errors(ncell, f, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure()\n",
    "pyplot.loglog(1/ncell, errors, \"o\", label=\"Numeric error\")\n",
    "pyplot.loglog(1/ncell, 1/ncell, label=\"$h^{-1}$\")\n",
    "pyplot.loglog(1/ncell, 1/ncell**2, label=\"$h^{-2}$\")\n",
    "pyplot.xlabel(\"$h$\")\n",
    "pyplot.ylabel(\"$\\|u - u^*\\|_2$\")\n",
    "pyplot.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse matrices\n",
    "\n",
    "We have 2nd order convergence. Notice that in 2D the grid-function norm is\n",
    "\n",
    "$$\n",
    "\\|u\\|_p = \\left(h_x h_y \\sum_i |u_i|^p\\right)^{\\frac{1}{p}}\n",
    "$$\n",
    "\n",
    "since we're a approximating a two-dimensional integral, and each little piece has area $h_x h_y$.\n",
    "\n",
    "We'd like to try on some bigger grids, but we run into a problem. The matrices we're making take a tremendously long time to invert. Let's see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile, pstats\n",
    "profiles = []\n",
    "ncell = [40, 50, 60, 70, 80, 90, 100]\n",
    "for n in ncell:\n",
    "    prof = cProfile.Profile()\n",
    "    prof.enable()\n",
    "    grid = Grid(n+1, n+1)\n",
    "    A, rhs = laplacian(grid, f, g)\n",
    "    u = numpy.linalg.solve(A, rhs.flatten())\n",
    "    prof.disable()\n",
    "    profiles.append(prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n, p in zip(ncell, profiles):\n",
    "    print(f\"***** Profile for {n}x{n} grid *****\")\n",
    "    pstats.Stats(p).sort_stats(pstats.SortKey.TIME).print_stats(3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the *sparsity* of the operator again, and some statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, _ = laplacian(Grid(11, 11), f, g)\n",
    "pyplot.figure()\n",
    "pyplot.spy(A);\n",
    "# Ainv = numpy.linalg.inv(A)\n",
    "# pyplot.figure()\\\n",
    "# pyplot.spy(Ainv);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Percentage of nonzeros: {100*numpy.prod(Ainv[numpy.nonzero(Ainv)].shape) / numpy.prod(A.shape):0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speeding up the solve\n",
    "\n",
    "So we're doing a lot of work storing lots of redundant zeros, and potentially lots of redundant work solving the equation.\n",
    "\n",
    "Instead, we can use a *sparse* matrix, provided by scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import scipy.sparse.linalg\n",
    "\n",
    "\n",
    "def laplacian_sparse(grid, f, g):\n",
    "    ndof = numpy.asarray(grid.ndof, dtype=int)\n",
    "    A = sp.lil_matrix((ndof, ndof))\n",
    "    X, Y = grid.XY\n",
    "    u0 = g(X, Y)\n",
    "    rhs = f(X, Y)\n",
    "    mask = numpy.zeros_like(X, dtype=int)\n",
    "    mask[1:-1,1:-1] = 1\n",
    "    mask = mask.flatten()\n",
    "    stencilx = 1/grid.hx**2 * numpy.array([-1, 0, 2, 0, -1])\n",
    "    stencily = 1/grid.hy**2 * numpy.array([0, -1, 2, -1, 0])\n",
    "    stencil = stencilx + stencily\n",
    "    for i in range(grid.Nx):\n",
    "        for j in range(grid.Ny):\n",
    "            row = grid.alpha(i, j)\n",
    "            if mask[row] == 0:\n",
    "                # Dirichlet bc\n",
    "                A[row, row] = 1\n",
    "                rhs[i, j] = u0[i, j]\n",
    "            else:\n",
    "                stencili = numpy.asarray([grid.alpha(*ij) for ij in\n",
    "                                          [(i-1, j), (i, j-1), (i, j), (i, j+1), (i+1, j)]])\n",
    "                smask = mask[stencili]\n",
    "                cols = stencili[smask == 1]\n",
    "                A[row, cols] = stencil[smask == 1]\n",
    "                # Lift boundary contribution to RHS\n",
    "                bdycols = stencili[smask == 0]\n",
    "                rhs[i, j] -= stencil[smask == 0] @ u0.reshape(-1)[bdycols]\n",
    "    return A.tocsr(), rhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid = Grid(41, 41)\n",
    "A, rhs = laplacian_sparse(grid, f, g)\n",
    "u = sp.linalg.spsolve(A, rhs.flatten(), use_umfpack=True)\n",
    "grid.contourf(u, levels=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Check this solution actually converges at second order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile, pstats\n",
    "profiles = []\n",
    "ncell = [40, 50, 60, 70, 80, 80, 100]\n",
    "for n in ncell:\n",
    "    prof = cProfile.Profile()\n",
    "    prof.enable()\n",
    "    grid = Grid(n+1, n+1)\n",
    "    A, rhs = laplacian_sparse(grid, f, g)\n",
    "    u = sp.linalg.spsolve(A, rhs.flatten())\n",
    "    prof.disable()\n",
    "    profiles.append(prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n, p in zip(ncell, profiles):\n",
    "    print(f\"***** Profile for {n}x{n} grid *****\")\n",
    "    pstats.Stats(p).sort_stats(pstats.SortKey.TIME).print_stats(3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A more efficient implementation\n",
    "\n",
    "OK, so now the creation of the matrix is the most expensive bit. We can try and fix this by directly creating a CSR matrix (rather than this linked-list thing), and jitting it with numba. We need to refactor the code a little (to move the jittable region into a separate function).\n",
    "\n",
    "For a CSR matrix we need to guess how big our data structures will be. Since we will have at most 5 entries per row, the value and colidx arrays are five times the number of degrees of freedom (rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@numba.jit(nopython=True) # warn if we couldn't compile\n",
    "def make_csr(stencil, mask, hx, hy, Nx, Ny, u0, rhs):\n",
    "    ndof = Nx * Ny\n",
    "    ai = numpy.zeros(ndof+1, dtype=numpy.int32)\n",
    "    aj = numpy.zeros(ndof*5, dtype=numpy.int32)\n",
    "    av = numpy.zeros(ndof*5, dtype=numpy.float64)\n",
    "\n",
    "    ajptr = 0\n",
    "    u0 = u0.flatten()\n",
    "    for i in range(Nx):\n",
    "        for j in range(Ny):\n",
    "            row = i*Ny + j\n",
    "            if mask[row] == 0:\n",
    "                ai[row+1] = 1 + ai[row]\n",
    "                aj[ajptr] = row\n",
    "                av[ajptr] = 1\n",
    "                ajptr += 1\n",
    "                rhs[i, j] = u0[row]\n",
    "            else:\n",
    "                stencili = numpy.asarray([i_*Ny + j_ for (i_, j_) in\n",
    "                                          [(i-1, j), (i, j-1), (i, j), (i, j+1), (i+1, j)]])\n",
    "                smask = mask[stencili]\n",
    "                cols = stencili[smask == 1]\n",
    "                ncol = len(cols)\n",
    "                ai[row+1] = len(cols) + ai[row]\n",
    "                aj[ajptr:ajptr+ncol] = cols\n",
    "                av[ajptr:ajptr+ncol] = stencil[smask == 1]\n",
    "                ajptr += ncol\n",
    "                # Lift boundary contribution to RHS\n",
    "                bdycols = stencili[smask == 0]\n",
    "                rhs[i, j] -= stencil[smask == 0] @ u0[bdycols]\n",
    "    return ai, aj, av\n",
    "\n",
    "def laplacian_sparse_csr(grid, f, g):\n",
    "    ndof = numpy.asarray(grid.ndof, dtype=int)\n",
    "    X, Y = grid.XY\n",
    "    u0 = g(X, Y)\n",
    "    rhs = f(X, Y)\n",
    "    mask = numpy.zeros_like(X, dtype=int)\n",
    "    mask[1:-1,1:-1] = 1\n",
    "    mask = mask.flatten()\n",
    "    stencilx = 1/grid.hx**2 * numpy.array([-1, 0, 2, 0, -1])\n",
    "    stencily = 1/grid.hy**2 * numpy.array([0, -1, 2, -1, 0])\n",
    "    stencil = stencilx + stencily\n",
    "    ai, aj, av = make_csr(stencil, mask, grid.hx, grid.hy, grid.Nx, grid.Ny, u0, rhs)\n",
    "    return sp.csr_matrix((av, aj, ai), shape=(ndof, ndof)), rhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile, pstats\n",
    "profiles = []\n",
    "ncell = [40, 50, 60, 70, 80, 80, 100]\n",
    "for n in ncell:\n",
    "    prof = cProfile.Profile()\n",
    "    prof.enable()\n",
    "    grid = Grid(n+1, n+1)\n",
    "    A, rhs = laplacian_sparse_csr(grid, f, g)\n",
    "    u = sp.linalg.spsolve(A, rhs.flatten())\n",
    "    prof.disable()\n",
    "    profiles.append(prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, p in zip(ncell, profiles):\n",
    "    print(f\"***** Profile for {n}x{n} grid *****\")\n",
    "    pstats.Stats(p).sort_stats(pstats.SortKey.TIME).print_stats(3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithmic performance of sparse direct solvers\n",
    "\n",
    "Now, finally, the solve is back at the top of our profile. Let's see how it scales with the number of dofs.\n",
    "\n",
    "We split the work into three phases\n",
    "\n",
    "1. Assembly of the operator (matrix $A$)\n",
    "2. Factoring the matrix into sparse $LU$ form\n",
    "3. Solving the problem by forward-backward substitution.\n",
    "\n",
    "For these sparse operators and the sparse direct solver we expect complexity\n",
    "\n",
    "1. Assembly $\\mathcal{O}(n)$\n",
    "2. Factoring $\\mathcal{O}(n^{3/2})$\n",
    "3. Solve $\\mathcal{O}(n \\log n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: Add LU forwards-backward substitution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "ns = numpy.geomspace(16, 1024, num=7, dtype=numpy.int32)\n",
    "factor_times = []\n",
    "lu_solve_times = []\n",
    "assemble_times = []\n",
    "for n in ns:\n",
    "    grid = Grid(n+1,n+1)\n",
    "    start = time.time()\n",
    "    A, rhs = laplacian_sparse_csr(grid, f, g)\n",
    "    end = time.time()\n",
    "    assemble_times.append(end - start)\n",
    "    print(f\"Assemble on {n}x{n} grid took {assemble_times[-1]:.2f}s\")\n",
    "    start = time.time() \n",
    "    lu = sp.linalg.splu(A.tocsc())\n",
    "    end = time.time()\n",
    "    factor_times.append(end - start)\n",
    "    print(f\"Factor on {n}x{n} grid took {factor_times[-1]:.2f}s\")\n",
    "    start = time.time()\n",
    "    u = lu.solve(rhs.flatten())\n",
    "    end = time.time()\n",
    "    lu_solve_times.append(end - start)\n",
    "    print(f\"Solve on {n}x{n} grid took {lu_solve_times[-1]:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid.contourf(u, levels=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndof = (ns+1)**2\n",
    "pyplot.figure()\n",
    "pyplot.loglog(ndof, assemble_times, \"o\", label=\"Assembly\")\n",
    "pyplot.loglog(ndof, factor_times, \"o\", label=\"Factor\")\n",
    "pyplot.loglog(ndof, lu_solve_times, \"o\", label=\"Solve\")\n",
    "ndof = ndof[3:]\n",
    "pyplot.loglog(ndof, ndof/1e6, label=\"$\\mathcal{O}(n)$\")\n",
    "pyplot.loglog(ndof, ndof**(3/2)/1e8, label=\"$\\mathcal{O}(n^{3/2})$\")\n",
    "pyplot.loglog(ndof, ndof*numpy.log(ndof)/1e7, label=\"$\\mathcal{O}(n \\log n)$\")\n",
    "pyplot.xlabel(\"Number of dofs\")\n",
    "pyplot.ylabel(\"Time (s)\")\n",
    "pyplot.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the factoring is clearly $n^{3/2}$, assembly looks like it's $n$. The solve itself is rather hard to judge, I suspect it's $n\\log n$, but we're observing probably cache effects for the smaller problems.\n",
    "\n",
    "Having now solved stationary problems (with no time derivative) we will move on to 2D time-dependent problems, using the *heat equation* as a first example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
