<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Domain decomposition and data parallelism #  In this exercise, we&rsquo;re going to look at some of the implementation steps involved in domain-decomposing a finite difference computation.
The particular case we are going to consider is that of edge detection in grayscale images, and subsequent reconstruction of the original image from the detected eges.
Introduction and background #  A particularly simple way of detecting the edges in an image is to convolve it with a Laplacian kernel."><meta name=theme-color content="#FFFFFF"><meta property="og:title" content="1-D domain decomposition"><meta property="og:description" content="Domain decomposition and data parallelism #  In this exercise, we&rsquo;re going to look at some of the implementation steps involved in domain-decomposing a finite difference computation.
The particular case we are going to consider is that of edge detection in grayscale images, and subsequent reconstruction of the original image from the detected eges.
Introduction and background #  A particularly simple way of detecting the edges in an image is to convolve it with a Laplacian kernel."><meta property="og:type" content="article"><meta property="og:url" content="https://teaching.wence.uk/comp4187/exercises/parallel/domain-decomp-simple/"><meta property="article:modified_time" content="2024-02-14T14:35:09+00:00"><title>1-D domain decomposition | COMP4187 – Parallel Scientific Computing II</title><link rel=manifest href=/comp4187/manifest.json><link rel=icon href=/comp4187/favicon.png type=image/x-icon><link rel=stylesheet href=/comp4187/book.min.0cb0b7d6a1ed5d0e95321cc15edca4d6e9cc406149d1f4a3f25fd532f6a3bb38.css integrity="sha256-DLC31qHtXQ6VMhzBXtyk1unMQGFJ0fSj8l/VMvajuzg="><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:true},{left:"$",right:"$",display:false},{left:"\\(",right:"\\)",display:false},{left:"\\[",right:"\\]",display:true}]})});</script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><nav><div class=book-brand><img class=book-center src=/comp4187/logo.svg alt=Logo><h2><a href=/comp4187>COMP4187 – Parallel Scientific Computing II</a></h2></div><ul><li><span>Administrivia</span><ul><li><a href=/comp4187/setup/jupyter/>Jupyter</a></li><li><a href=/comp4187/setup/mpi/>MPI</a></li></ul></li><li><span>Exercises</span><ul><li><span>Parallel</span><ul><li><a href=/comp4187/exercises/parallel/hello/>Parallel Hello World</a></li><li><a href=/comp4187/exercises/parallel/pi/>Calculating π</a></li><li><a href=/comp4187/exercises/parallel/domain-decomp-simple/ class=active>1-D domain decomposition</a></li><li><a href=/comp4187/exercises/parallel/pingpong/>Ping-pong latency</a></li></ul></li><li><a href=/comp4187/exercises/coarse-grid/>Coarse Grid Operator</a></li><li><a href=/comp4187/exercises/finite-differences/>Finite Differences</a></li><li><a href=/comp4187/exercises/two-grid/>Two-Grid Iteration</a></li><li><a href=/comp4187/exercises/norms/>Norms</a></li></ul></li><li><span>Notes</span><ul><li><span>Lectures: Numerics</span><ul><li><a href=/comp4187/lectures/numerics/lecture1/>Lecture 1: Time-stepping</a></li><li><a href=/comp4187/lectures/numerics/lecture2/>Lecture 2: Time-stepping</a></li><li><a href=/comp4187/lectures/numerics/lecture3/>Lecture 3: Time-stepping</a></li><li><a href=/comp4187/lectures/numerics/lecture4/>Lecture 4: Finite Differences</a></li><li><a href=/comp4187/lectures/numerics/lecture5/>Lecture 5: Finite Differences</a></li><li><a href=/comp4187/lectures/numerics/lecture6/>Lecture 6: Finite Differences</a></li><li><a href=/comp4187/lectures/numerics/lecture7/>Lecture 7: Linear Solvers</a></li><li><a href=/comp4187/lectures/numerics/lecture8/>Lecture 8: Linear Solvers</a></li><li><a href=/comp4187/lectures/numerics/lecture9/>Lecture 9: Multigrid</a></li></ul></li><li><a href=/comp4187/lectures/mpi/>MPI</a><ul><li><a href=/comp4187/lectures/mpi/point-to-point/>Point-to-point messaging in MPI</a></li><li><a href=/comp4187/lectures/mpi/point-to-point-nb/>Non-blocking point-to-point messaging</a></li><li><a href=/comp4187/lectures/mpi/collectives/>Collectives</a></li><li><a href=/comp4187/lectures/mpi/advanced/>Advanced topics</a></li><li><a href=/comp4187/lectures/mpi/petsc4py/>PETSc and petsc4py</a></li><li><a href=/comp4187/lectures/mpi/live-notes/>Term 2: live lecture notes</a></li></ul></li></ul></li><li><a href=/comp4187/coursework/>Coursework 1: Euler-Bernoulli Beam Theory</a></li><li><a href=/comp4187/coursework2/>Coursework 2: multigrid solvers</a></li><li><a href=/comp4187/acknowledgements/>Acknowledgements</a></li><li><span>Past editions</span><ul><li><span>2020/21</span><ul><li><a href=/comp4187/past-editions/2020-21/term1/>Term 1: numerics</a></li><li><a href=/comp4187/past-editions/2020-21/term2/>Term 2: parallel computing</a></li><li><a href=/comp4187/past-editions/2020-21/coursework/>Coursework: a 3D multigrid solver</a></li></ul></li></ul></li></ul></nav><script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/comp4187/svg/menu.svg class=book-icon alt=Menu></label>
<strong>1-D domain decomposition</strong>
<label for=toc-control><img src=/comp4187/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#domain-decomposition-and-data-parallelism>Domain decomposition and data parallelism</a><ul><li><a href=#introduction-and-background>Introduction and background</a></li><li><a href=#implementation>Implementation</a><ul><li><a href=#data-structures>Data structures</a></li><li><a href=#data-distribution-and-parallelisation>Data distribution and parallelisation</a></li></ul></li></ul></li></ul></nav></aside></header><article class=markdown><h1 id=domain-decomposition-and-data-parallelism>Domain decomposition and data parallelism
<a class=anchor href=#domain-decomposition-and-data-parallelism>#</a></h1><p>In this exercise, we&rsquo;re going to look at some of the implementation
steps involved in domain-decomposing a finite difference computation.</p><p>The particular case we are going to consider is that of edge detection
in grayscale images, and subsequent reconstruction of the original
image from the detected eges.</p><h2 id=introduction-and-background>Introduction and background
<a class=anchor href=#introduction-and-background>#</a></h2><p>A particularly simple way of detecting the edges in an image is to
convolve it with a <a href=https://aishack.in/tutorials/sobel-laplacian-edge-detectors/>Laplacian
kernel</a>.
That is, given some image $I$, we can obtain its edges with</p><p>$$
E = \nabla^2 I.
$$</p><p>By now, you should be familiar with the <a href=https://en.wikipedia.org/wiki/Five-point_stencil>five-point finite
difference stencil</a>,
which we&rsquo;ll use heree for discretisation.</p><p>Having computed the edges, $E$, we can (approximately) reconstruct the
image $I$ by applying the inverse $\left(\nabla^2\right)^{-1}$. The
approximate reconstructed image is</p><p>$$
I^r = \left(\nabla^2\right)^{-1} E.
$$</p><p>We discretise the image as a 2D array, computing the edges can be done
in one step</p><p>$$
E_{i, j} = I_{i-1, j} + I_{i+1, j} + I_{i, j-1} + I_{i, j+1} - 4I_{i,j}
$$</p><p>for all pixels $i, j$ in the image.</p><p>To reconstruct the image, we will use a <a href=https://en.wikipedia.org/wiki/Jacobi_method>Jacobi
iteration</a>, given an
initial guess for the reconstructed image, $I^{r, 0}$, we set
$k = 0$ and then an improved guess is given by</p><p>$$
I_{i,j}^{r,k+1} = \frac{1}{4}\left(I_{i-1, j}^{r,k} + I_{i+1,j}^{r,k} +
I_{i,j-1}^{r,k} + I_{i,j+1}^{r,k} - E_{i,j}\right)
$$
for all pixels $i, j$ in the image. You&rsquo;ll note that this is exactly
the Jacobi smoother we saw last term.</p><p>After many many iterations ($k \to \infty$), this will converge to a
good approximation to the initial image.</p><blockquote class="book-hint danger"><span><strong>WARNING, WARNING</strong>. As we saw last term when looking at multigrid
methods, this is a <em>terrible</em> way of inverting the
Laplacian, we&rsquo;re using it to illustrate some domain decomposition and
parallelisation approaches: the multilevel stuff is to come!</span></blockquote><h2 id=implementation>Implementation
<a class=anchor href=#implementation>#</a></h2><p>This code lives in the <code>code/parallel/dd-image/</code> subdirectory. There
are some sample images in the <code>images</code> subdirectory.</p><h3 id=data-structures>Data structures
<a class=anchor href=#data-structures>#</a></h3><p>The image itself is stored as a 2D array. We use domain decomposition
to divide up the global image between processes. Here we are only
using a 1-D decomposition (which is slightly easier to program, but
less efficient). In real life you&rsquo;d use a 2-D decomposition.</p><p>The idea is that each process owns a contigous slice of the total
image. To compute the stencil that updates each pixel in the image, we
need to access neighbouring values. On the global image boundary,
we&rsquo;ll use zero Dirichlet conditions. Where two processes meet, they
will have to communicate to exchange values.</p><div class="book-columns flex flex-wrap"><div class="flex-even markdown-inner"><figure style=width:100%><img class=scaled src=https://teaching.wence.uk/comp4187/images/manual/image-two-ranks.svg alt="Decomposition of a 2D image between two processes."><figcaption><p>Decomposition of a 2D image between two processes.</p></figcaption></figure></div><div class="flex-even markdown-inner"><figure style=width:82%><img class=scaled src=https://teaching.wence.uk/comp4187/images/manual/image-two-ranks-split.svg alt="Decomposition of a 2D image showing separation of memory"><figcaption><p>Decomposition of a 2D image showing separation of memory</p></figcaption></figure></div></div><p>The nice way of thinking about this is to separate the communication
and computation phases using <em>global</em> and <em>local</em> vectors. <em>Global</em>
vectors represent the process&rsquo;s portion of the image which it is
responsible for updating. <em>Local</em> vectors are padded with values from
either the Dirichlet data or the neighbouring process, so that we can
compute on them without needing to communicate, or insert conditional
branches in the inner loop.</p><p>A computation phase, to reconstruct the image from edges is, in
pseudo-code, something like:</p><div class=highlight><pre style=color:#272822;background-color:#fafafa><code class=language-python data-lang=python><span style=color:#00a8c8>def</span> <span style=color:#75af00>update</span><span style=color:#111>(</span><span style=color:#111>uold</span><span style=color:#111>,</span> <span style=color:#111>unew</span><span style=color:#111>):</span>
    <span style=color:#d88200>&#34;&#34;&#34;Update unew &lt;- stencil(uold)
</span><span style=color:#d88200>
</span><span style=color:#d88200>    Both uold and unew are global vectors
</span><span style=color:#d88200>    &#34;&#34;&#34;</span>
    <span style=color:#111>ulocal</span> <span style=color:#f92672>=</span> <span style=color:#111>global_to_local</span><span style=color:#111>(</span><span style=color:#111>uold</span><span style=color:#111>)</span>
    <span style=color:#111>ulocalnew</span> <span style=color:#f92672>=</span> <span style=color:#111>apply_stencil</span><span style=color:#111>(</span><span style=color:#111>ulocal</span><span style=color:#111>)</span>
    <span style=color:#111>unew</span> <span style=color:#f92672>=</span> <span style=color:#111>local_to_global</span><span style=color:#111>(</span><span style=color:#111>ulocalnew</span><span style=color:#111>)</span>
    <span style=color:#00a8c8>return</span> <span style=color:#111>unew</span>
</code></pre></div><p>To implement this, we need to carry around information about the grid
that decomposes the global image.</p><p>The <code>global_to_local</code> and <code>local_to_global</code> calls communicate halo (or
ghost) values between processes. The <code>apply_stencil</code> then operates on
purely local data (it just has to iterate over the correct part of the
image).</p><h3 id=data-distribution-and-parallelisation>Data distribution and parallelisation
<a class=anchor href=#data-distribution-and-parallelisation>#</a></h3><p>There are three steps to the parallelisation of the code.</p><ol><li>Having read the image on a single process, distribute across all
the processes in the communicator;</li><li>Run the edge detection, and then reconstruction routines (using the
ideas described above);</li><li>Gather the distributed, reconstructed, image to a single rank to
write the output.</li></ol><blockquote class="book-hint info"><span>For really large-scale computations, it is best to use parallel
output, but we&rsquo;re not going to do that here.</span></blockquote><p>The template code implements this algorithmic workflow, but has
stubbed out a bunch of the functions. Your job is to implement the
different pieces and put it together.</p><blockquote class=exercise><h3>Exercise</h3><span>Implement distribution of the image array across the available
processes. You should use
<a href=https://rookiehpc.com/mpi/docs/mpi_scatter.php><code>MPI_Scatter</code></a> or
<a href=https://rookiehpc.com/mpi/docs/mpi_scatterv.php><code>MPI_Scatterv</code></a>
depending on whether the number of processes evenly divides the number
of image rows or not.</span></blockquote><p>With this step done, you should be able to run in parallel and see the
different outputs. Note that at this point, the boundary values will
be incorrect. So our next step is to implement the correct
<code>global_to_local</code> and <code>local_to_global</code> routines.</p><blockquote class=exercise><h3>Exercise</h3><span><p>Use <a href=https://teaching.wence.uk/comp4187/lectures/mpi/point-to-point-nb/>non-blocking</a> sends and
receives to implement the data exchange necessary to update ghost
values in <code>global_to_local</code> and <code>local_to_global</code>. Think about where
you need to actually transfer data: do you need to do message exchange
in both routines, or can you get away with local copies for one of
them?</p><details><summary>Hint</summary><div class=markdown-inner>For these kind of things, I always find it helpful to draw some
pictures of where the data live.</div></details></span></blockquote><p>Finally we need to gather the resulting images onto a single rank for
writing. Having implemented the distribution by scattering data, this
should be reasonably straightforward: it&rsquo;s the inverse operation,
using <a href=https://rookiehpc.com/mpi/docs/mpi_gather.php><code>MPI_Gather</code></a> or
<a href=https://rookiehpc.com/mpi/docs/mpi_gatherv.php><code>MPI_Gatherv</code></a> as
appropriate.</p></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/wenceorg/comp4187/commit/9271858aa631161252031b9cd38d4da1c5c802a0 title="Last modified by Lawrence Mitchell | February 14, 2024" target=_blank rel=noopener><img src=/comp4187/svg/calendar.svg class=book-icon alt=Calendar>
<span>February 14, 2024</span></a></div><div><a class="flex align-center" href=https://github.com/wenceorg/comp4187/edit/main/site/content/exercises/parallel/domain-decomp-simple.md target=_blank rel=noopener><img src=/comp4187/svg/edit.svg class=book-icon alt=Edit>
<span>Edit this page</span></a></div></div><div class="flex flex-wrap align-right"><p>© 2020&ndash; <a href=mailto:lawrence@wence.uk>Lawrence Mitchell</a>, <a href=https://annereinarz.github.io>Anne Reinarz</a> & <a href=https://www.dur.ac.uk/>Durham University</a>.</p><p><a rel=license href=http://creativecommons.org/licenses/by-sa/4.0/><img alt="Creative Commons License" style=border-width:0 src=/comp4187/cc-by-sa.svg></a>
This work is licensed under a <a rel=license href=http://creativecommons.org/licenses/by-sa/4.0/>Creative
Commons Attribution-ShareAlike 4.0 International License</a>.</p></div></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><nav id=TableOfContents><ul><li><a href=#domain-decomposition-and-data-parallelism>Domain decomposition and data parallelism</a><ul><li><a href=#introduction-and-background>Introduction and background</a></li><li><a href=#implementation>Implementation</a><ul><li><a href=#data-structures>Data structures</a></li><li><a href=#data-distribution-and-parallelisation>Data distribution and parallelisation</a></li></ul></li></ul></li></ul></nav></aside></main></body></html>