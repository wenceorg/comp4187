<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>MPI on COMP4187 – Parallel Scientific Computing II</title><link>https://teaching.wence.uk/comp4187/lectures/mpi/</link><description>Recent content in MPI on COMP4187 – Parallel Scientific Computing II</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://teaching.wence.uk/comp4187/lectures/mpi/index.xml" rel="self" type="application/rss+xml"/><item><title>Point-to-point messaging in MPI</title><link>https://teaching.wence.uk/comp4187/lectures/mpi/point-to-point/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://teaching.wence.uk/comp4187/lectures/mpi/point-to-point/</guid><description>Pairwise message exchange # The simplest form of communication in MPI is a pairwise exchange of a message between two processes.
In MPI, communication via messages is two-sided1. That is, for every message one process sends, there must be a matching receive call by another process.
Cartoon of sending a message between two processes
We need to fill in some details
How will we describe &amp;ldquo;data&amp;rdquo; How will we identify processes How will the receiver know which message to put where?</description></item><item><title>Non-blocking point-to-point messaging</title><link>https://teaching.wence.uk/comp4187/lectures/mpi/point-to-point-nb/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://teaching.wence.uk/comp4187/lectures/mpi/point-to-point-nb/</guid><description>Non-blocking messages # As well as the blocking point to point messaging we saw last time, MPI also offers non-blocking versions.
These functions all return immediately, and provide a &amp;ldquo;request&amp;rdquo; object that we can then either wait for completion with or inspect to check if the message has been sent/received.
The function signatures for MPI_Isend and MPI_Irecv are:
int MPI_Isend(const void *buffer, int count, MPI_Datatype dtype, int dest, int tag, MPI_Comm comm, MPI_Request *request); int MPI_Irecv(void *buffer, int count, MPI_Datatype dtype, int dest, int tag, MPI_Comm comm, MPI_Request *request); The mpi4py versions are:</description></item><item><title>Collectives</title><link>https://teaching.wence.uk/comp4187/lectures/mpi/collectives/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://teaching.wence.uk/comp4187/lectures/mpi/collectives/</guid><description>Collective communication # Point-to-point messages are sufficient to write all the parallel algorithms we might want. However, they might not necessarily be the most efficient.
As motivation, let&amp;rsquo;s think about the time we would expect a reduction (combination of values) to take if we send messages in a 1-D ring of processes.
Recall from the ping-pong exercise that our model for the length of time it takes to send a message with $B$ bytes is</description></item><item><title>Advanced topics</title><link>https://teaching.wence.uk/comp4187/lectures/mpi/advanced/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://teaching.wence.uk/comp4187/lectures/mpi/advanced/</guid><description>Some pointers to more advanced features of MPI # Communicator manipulation # We saw that we can distinguish point-to-point messages by providing different tags, but that there was no such facility for collective operations. Moreover, a collective operation (by definition) involves all the processes in a communicator.
This raises two questions:
How can we have multiple collective operations without them interfering with each other; What if we want a collective operation, but using only a subset of the processes (e.</description></item><item><title>PETSc and petsc4py</title><link>https://teaching.wence.uk/comp4187/lectures/mpi/petsc4py/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://teaching.wence.uk/comp4187/lectures/mpi/petsc4py/</guid><description>A petsc4py Rosetta stone # PETSc itself has rather good documentation, both of the API and a user manual. The PETSc API has very consistent naming. Objects are created with XXXCreate. Where XXX stands for the object type name. For example, to create a vector (which has type Vec):
Vec v; VecCreate(MPI_COMM_WORLD, &amp;amp;v); To create a matrix (which has type Mat):
Mat m; MatCreate(MPI_COMM_WORLD, &amp;amp;m); In python-land, all object names are the same, and namespaced within the PETSc package.</description></item><item><title>Term 2: live lecture notes</title><link>https://teaching.wence.uk/comp4187/lectures/mpi/live-notes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://teaching.wence.uk/comp4187/lectures/mpi/live-notes/</guid><description>Lecture slides 2021/22 edition # Slides as produced during the live lectures. Recordings of the live sessions are available if you&amp;rsquo;re appropriately logged in. If you think you should have access but don&amp;rsquo;t, please get in touch.
2022-01-12: Notes, video, code.
Have a go at the hello world exercise which walks through setting up an environment with MPI installed.
2022-01-19: Notes, video.
We had a bit of a palaver with the network being terrible, so sorry to those attending online for the drop out in the second half.</description></item></channel></rss>